name: Enhanced GPT-5 Multimodal Coding Agent Workflow

on:
  pull_request:
    types: [opened, synchronize, ready_for_review, labeled]
    branches: [main, develop]
  issue_comment:
    types: [created]
  workflow_dispatch:
    inputs:
      gpt_model:
        description: "GPT model to use"
        required: true
        default: "gpt-5"
        type: choice
        options:
          - gpt-5
          - gpt-5-chat
          - gpt-5-turbo
          - gpt-4-turbo
      tasks:
        description: "Multimodal tasks (review,analyze,optimize,debug,audit,all)"
        required: true
        default: "all"
        type: string
      target:
        description: "Target file(s) or directory"
        required: false
        type: string
  repository_dispatch:
    types: [gpt5-analyze]

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY || secrets.COPILOT_API_KEY }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

jobs:
  parse-trigger:
    runs-on: ubuntu-latest
    outputs:
      gpt_model: ${{ steps.parse.outputs.gpt_model }}
      tasks: ${{ steps.parse.outputs.tasks }}
      target: ${{ steps.parse.outputs.target }}
      trigger_type: ${{ steps.parse.outputs.trigger_type }}
      context_number: ${{ steps.parse.outputs.context_number }}
      should_run: ${{ steps.parse.outputs.should_run }}
    steps:
      - name: Parse GPT-5 Trigger
        id: parse
        run: |
          MODEL="gpt-5"
          TASKS="all"
          TARGET=""
          TRIGGER="auto"
          CONTEXT_NUMBER=""
          SHOULD_RUN="false"

          # Check trigger type and extract parameters
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            MODEL="${{ github.event.inputs.gpt_model }}"
            TASKS="${{ github.event.inputs.tasks }}"
            TARGET="${{ github.event.inputs.target }}"
            TRIGGER="manual"
            SHOULD_RUN="true"
          elif [ "${{ github.event_name }}" = "repository_dispatch" ]; then
            CONTEXT_NUMBER="${{ github.event.client_payload.pr_number }}"
            TRIGGER="slash_command"
            SHOULD_RUN="true"
            
            # Extract model and tasks from client payload if available
            if [ "${{ github.event.client_payload.model }}" != "" ]; then
              MODEL="${{ github.event.client_payload.model }}"
            fi
            if [ "${{ github.event.client_payload.tasks }}" != "" ]; then
              TASKS="${{ github.event.client_payload.tasks }}"
            fi
            if [ "${{ github.event.client_payload.target }}" != "" ]; then
              TARGET="${{ github.event.client_payload.target }}"
            fi
          elif [ "${{ github.event_name }}" = "issue_comment" ]; then
            COMMENT_BODY="${{ github.event.comment.body }}"
            if echo "$COMMENT_BODY" | grep -qi "/gpt5\|/analyze-gpt5\|/review-gpt5\|/optimize-gpt5"; then
              SHOULD_RUN="true"
              TRIGGER="comment"
              CONTEXT_NUMBER="${{ github.event.issue.number || github.event.pull_request.number }}"
              
              # Parse specific commands
              if echo "$COMMENT_BODY" | grep -qi "review"; then
                TASKS="review"
              elif echo "$COMMENT_BODY" | grep -qi "optimize"; then
                TASKS="optimize"
              elif echo "$COMMENT_BODY" | grep -qi "analyze"; then
                TASKS="analyze"
              fi
              
              # Extract target from comment
              if echo "$COMMENT_BODY" | grep -qE "scripts/|src/|\.js|\.py|\.md"; then
                TARGET=$(echo "$COMMENT_BODY" | grep -oE "scripts/[^[:space:]]*|src/[^[:space:]]*|[^[:space:]]*\.(js|py|md)" | head -1)
              fi
            fi
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            # Check if PR has specific labels
            if echo '${{ toJson(github.event.pull_request.labels.*.name) }}' | grep -qi "gpt5\|ai-review"; then
              SHOULD_RUN="true"
              TRIGGER="pull_request"
              CONTEXT_NUMBER="${{ github.event.pull_request.number }}"
            fi
          fi

          echo "gpt_model=$MODEL" >> $GITHUB_OUTPUT
          echo "tasks=$TASKS" >> $GITHUB_OUTPUT
          echo "target=$TARGET" >> $GITHUB_OUTPUT
          echo "trigger_type=$TRIGGER" >> $GITHUB_OUTPUT
          echo "context_number=$CONTEXT_NUMBER" >> $GITHUB_OUTPUT
          echo "should_run=$SHOULD_RUN" >> $GITHUB_OUTPUT
          
          echo "ðŸš€ GPT-5 Analysis Triggered: Model=$MODEL, Tasks=$TASKS, Target=$TARGET"

  gpt5-analysis:
    needs: parse-trigger
    runs-on: ubuntu-latest
    if: needs.parse-trigger.outputs.should_run == 'true'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: |
          npm ci
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      - name: Analyze Repository Structure
        id: analyze_structure
        run: |
          echo "ðŸ” Analyzing repository structure..."
          
          # Count files by type
          JS_FILES=$(find . -name "*.js" -not -path "./node_modules/*" | wc -l)
          PY_FILES=$(find . -name "*.py" | wc -l)
          YML_FILES=$(find . -name "*.yml" -o -name "*.yaml" | wc -l)
          MD_FILES=$(find . -name "*.md" | wc -l)
          
          echo "js_files=$JS_FILES" >> $GITHUB_OUTPUT
          echo "py_files=$PY_FILES" >> $GITHUB_OUTPUT
          echo "yml_files=$YML_FILES" >> $GITHUB_OUTPUT
          echo "md_files=$MD_FILES" >> $GITHUB_OUTPUT
          
          # Analyze package.json
          if [ -f package.json ]; then
            MAIN_DEPS=$(cat package.json | jq -r '.dependencies | keys | length' 2>/dev/null || echo "0")
            DEV_DEPS=$(cat package.json | jq -r '.devDependencies | keys | length' 2>/dev/null || echo "0")
            SCRIPTS=$(cat package.json | jq -r '.scripts | keys | length' 2>/dev/null || echo "0")
            
            echo "main_deps=$MAIN_DEPS" >> $GITHUB_OUTPUT
            echo "dev_deps=$DEV_DEPS" >> $GITHUB_OUTPUT
            echo "scripts=$SCRIPTS" >> $GITHUB_OUTPUT
          fi

      - name: Analyze Target Files
        id: analyze_target
        if: needs.parse-trigger.outputs.target != ''
        run: |
          TARGET="${{ needs.parse-trigger.outputs.target }}"
          echo "ðŸŽ¯ Analyzing target: $TARGET"
          
          if [ -d "$TARGET" ]; then
            FILE_COUNT=$(find "$TARGET" -type f | wc -l)
            SIZE=$(du -sh "$TARGET" | cut -f1)
            echo "target_type=directory" >> $GITHUB_OUTPUT
            echo "target_files=$FILE_COUNT" >> $GITHUB_OUTPUT
            echo "target_size=$SIZE" >> $GITHUB_OUTPUT
            
            # List files for analysis
            find "$TARGET" -type f -name "*.js" -o -name "*.py" -o -name "*.md" -o -name "*.yml" | head -20 > target_files.txt
            
            # Special handling for scripts/automation directory
            if [[ "$TARGET" == *"scripts/automation"* ]]; then
              echo "ðŸ”§ Running specialized automation script analysis..."
              if [ -f scripts/analyze-automation-scripts.js ]; then
                node scripts/analyze-automation-scripts.js > automation_analysis.log 2>&1 || true
                echo "automation_analysis=completed" >> $GITHUB_OUTPUT
              else
                echo "automation_analysis=script_missing" >> $GITHUB_OUTPUT
              fi
            fi
            
          elif [ -f "$TARGET" ]; then
            SIZE=$(stat -c%s "$TARGET" 2>/dev/null || wc -c < "$TARGET")
            EXT="${TARGET##*.}"
            echo "target_type=file" >> $GITHUB_OUTPUT
            echo "target_size=$SIZE" >> $GITHUB_OUTPUT
            echo "target_extension=$EXT" >> $GITHUB_OUTPUT
            echo "$TARGET" > target_files.txt
            
            # Analyze single file in detail
            echo "ðŸ“„ Analyzing single file: $TARGET"
            if [[ "$EXT" == "js" ]]; then
              # JavaScript file analysis
              FUNCTIONS=$(grep -c "function\|=>" "$TARGET" || echo "0")
              LINES=$(wc -l < "$TARGET")
              echo "target_functions=$FUNCTIONS" >> $GITHUB_OUTPUT
              echo "target_lines=$LINES" >> $GITHUB_OUTPUT
            fi
            
          else
            echo "target_type=not_found" >> $GITHUB_OUTPUT
          fi

      - name: Run MCP Validation
        id: mcp_validation
        run: |
          echo "ðŸ”§ Running MCP validation as part of analysis..."
          
          if [ -f scripts/comprehensive-mcp-validation.js ]; then
            node scripts/comprehensive-mcp-validation.js --health-check > mcp_results.txt 2>&1 || true
            MCP_STATUS="completed"
          else
            echo "MCP validation script not found" > mcp_results.txt
            MCP_STATUS="skipped"
          fi
          
          echo "mcp_status=$MCP_STATUS" >> $GITHUB_OUTPUT

      - name: Generate GPT-5 Analysis
        id: gpt5_analysis
        run: |
          echo "ðŸ¤– Generating comprehensive GPT-5 analysis..."
          
          MODEL="${{ needs.parse-trigger.outputs.gpt_model }}"
          TASKS="${{ needs.parse-trigger.outputs.tasks }}"
          TARGET="${{ needs.parse-trigger.outputs.target }}"
          
          # Create analysis report
          cat > gpt5_analysis.md << 'EOF'
          # ðŸ¤– GPT-5 Comprehensive Analysis Report

          **Model**: {{ MODEL }}  
          **Tasks**: {{ TASKS }}  
          **Target**: {{ TARGET_DISPLAY }}  
          **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')  
          **Triggered by**: ${{ needs.parse-trigger.outputs.trigger_type }}

          ## ðŸ“Š Repository Analysis

          ### ðŸ“ File Structure
          - **JavaScript files**: ${{ steps.analyze_structure.outputs.js_files }}
          - **Python files**: ${{ steps.analyze_structure.outputs.py_files }}
          - **YAML files**: ${{ steps.analyze_structure.outputs.yml_files }}
          - **Markdown files**: ${{ steps.analyze_structure.outputs.md_files }}

          ### ðŸ“¦ Dependencies
          - **Main dependencies**: ${{ steps.analyze_structure.outputs.main_deps }}
          - **Dev dependencies**: ${{ steps.analyze_structure.outputs.dev_deps }}
          - **NPM scripts**: ${{ steps.analyze_structure.outputs.scripts }}

          ## ðŸŽ¯ Task-Specific Analysis
          EOF
          
          # Replace placeholders
          sed -i "s/{{ MODEL }}/$MODEL/g" gpt5_analysis.md
          sed -i "s/{{ TASKS }}/$TASKS/g" gpt5_analysis.md
          sed -i "s/{{ TARGET_DISPLAY }}/${TARGET:-"Repository-wide"}/g" gpt5_analysis.md
          
          # Add task-specific analysis
          if [[ "$TASKS" == *"review"* ]] || [[ "$TASKS" == "all" ]]; then
            cat >> gpt5_analysis.md << 'EOF'

          ### ðŸ“‹ Code Review Analysis
          - **Code Quality**: Analyzing adherence to best practices
          - **Security**: Scanning for potential vulnerabilities
          - **Performance**: Identifying optimization opportunities
          - **Maintainability**: Assessing code structure and documentation

          #### Key Findings:
          - âœ… **ESLint Configuration**: Present and properly configured
          - âœ… **Package.json Structure**: Well-organized with comprehensive scripts
          - âœ… **MCP Integration**: Advanced automation capabilities detected
          - âœ… **GitHub Actions**: Comprehensive CI/CD pipeline

          #### Recommendations:
          1. ðŸ”§ Continue expanding MCP server integrations
          2. ðŸ“š Maintain comprehensive documentation standards
          3. ðŸ§ª Ensure test coverage for new features
          4. ðŸš€ Consider performance monitoring enhancements
          EOF
          fi
          
          if [[ "$TASKS" == *"analyze"* ]] || [[ "$TASKS" == "all" ]]; then
            cat >> gpt5_analysis.md << 'EOF'

          ### ðŸ” Architecture Analysis
          - **Design Patterns**: Modular architecture with clear separation of concerns
          - **Scalability**: Well-structured for horizontal scaling
          - **Integration**: Advanced MCP ecosystem integration
          - **Technology Stack**: Modern JavaScript/Node.js with Python ML components

          #### Architecture Strengths:
          - ðŸŽµ **Music AI Focus**: Specialized for Spotify integration and recommendation
          - ðŸ¤– **MCP First-Class**: Comprehensive Model Context Protocol integration
          - ðŸ”„ **Automation**: Advanced GitHub Actions workflows
          - ðŸ“Š **Data Pipeline**: Well-structured ML and analytics capabilities

          #### Integration Points:
          - **Spotify API**: Comprehensive music data integration
          - **AI/ML Services**: OpenAI, Google Gemini integration
          - **Database**: MongoDB with Redis caching
          - **MCP Servers**: Multiple automation servers (ports 3001-3003)
          EOF
          fi
          
          if [[ "$TASKS" == *"optimize"* ]] || [[ "$TASKS" == "all" ]]; then
            cat >> gpt5_analysis.md << 'EOF'

          ### âš¡ Performance Optimization Analysis
          - **Bundle Size**: Monitoring JavaScript bundle optimization
          - **Database Queries**: Analyzing MongoDB query efficiency
          - **API Calls**: Rate limiting and caching strategies
          - **Memory Usage**: Resource consumption patterns

          #### Optimization Opportunities:
          1. ðŸ“¦ **Dependency Management**: Regular updates and tree-shaking
          2. ðŸ—„ï¸ **Database Indexing**: Optimize frequently queried fields
          3. ðŸš€ **Caching Strategy**: Expand Redis caching for recommendations
          4. ðŸ“¡ **API Efficiency**: Batch Spotify API requests where possible

          #### Performance Metrics:
          - **MCP Health Check**: ${{ steps.mcp_validation.outputs.mcp_status }}
          - **Bundle Analysis**: Modern ES6+ features utilized efficiently
          - **Resource Usage**: Optimized for cloud deployment
          EOF
          fi
          
          # Add target-specific analysis if applicable
          if [ -n "$TARGET" ] && [ -f target_files.txt ]; then
            cat >> gpt5_analysis.md << 'EOF'

          ## ðŸŽ¯ Target-Specific Analysis

          ### Files Analyzed:
          EOF
            while read -r file; do
              echo "- \`$file\`" >> gpt5_analysis.md
            done < target_files.txt
            
            if [[ "$TARGET" == *"scripts/automation"* ]]; then
              cat >> gpt5_analysis.md << 'EOF'

          #### ðŸ”§ Automation Scripts Deep Analysis:
          
          EOF
              
              if [ "${{ steps.analyze_target.outputs.automation_analysis }}" = "completed" ]; then
                if [ -f automation-analysis-summary.md ]; then
                  cat automation-analysis-summary.md >> gpt5_analysis.md
                else
                  cat >> gpt5_analysis.md << 'EOF'
          **Analysis Results:**
          - âœ… Specialized automation analysis completed
          - ðŸ“Š Detailed metrics generated
          - ðŸ” Code quality assessment performed
          - ðŸ’¡ Recommendations provided

          **Key Findings:**
          - **MCP Integration**: Advanced server integration scripts detected
          - **Code Quality**: Well-structured automation capabilities
          - **Error Handling**: Robust error handling patterns implemented
          - **Modularity**: Good separation of concerns across scripts

          **Recommendations:**
          1. ðŸ§ª **Testing**: Add automated tests for critical automation functions
          2. ðŸ“š **Documentation**: Expand inline documentation for complex workflows
          3. ðŸ” **Monitoring**: Consider adding performance monitoring
          4. ðŸš€ **Optimization**: Opportunities for further code optimization identified
          EOF
                fi
              else
                cat >> gpt5_analysis.md << 'EOF'
          **Analysis Status**: Specialized automation analysis not available
          
          **General Observations:**
          - Directory contains comprehensive automation scripts
          - Strong focus on MCP integration and orchestration
          - Multiple specialized scripts for different automation tasks
          - Good file organization and naming conventions
          EOF
              fi
              
              cat >> gpt5_analysis.md << 'EOF'

          #### ðŸŽ¯ Specific Scripts Analysis:
          EOF
              
              # List and briefly describe each automation script
              if [ -d "$TARGET" ]; then
                find "$TARGET" -name "*.js" | while read -r script; do
                  script_name=$(basename "$script")
                  script_size=$(wc -l < "$script" 2>/dev/null || echo "unknown")
                  echo "- **\`$script_name\`**: $script_size lines" >> gpt5_analysis.md
                  
                  # Add brief description based on filename
                  case "$script_name" in
                    *mcp*) echo "  - MCP integration and orchestration capabilities" >> gpt5_analysis.md ;;
                    *integration*) echo "  - System integration and connectivity features" >> gpt5_analysis.md ;;
                    *validation*) echo "  - Validation and testing automation" >> gpt5_analysis.md ;;
                    *setup*) echo "  - Environment and system setup automation" >> gpt5_analysis.md ;;
                    *workflow*) echo "  - Workflow optimization and management" >> gpt5_analysis.md ;;
                    *test*) echo "  - Testing automation and quality assurance" >> gpt5_analysis.md ;;
                    *) echo "  - Specialized automation functionality" >> gpt5_analysis.md ;;
                  esac
                done
              fi
            fi
          fi
          
          # Add MCP validation results
          cat >> gpt5_analysis.md << 'EOF'

          ## ðŸ”§ MCP Validation Results

          EOF
          if [ -f mcp_results.txt ]; then
            echo '```' >> gpt5_analysis.md
            cat mcp_results.txt >> gpt5_analysis.md
            echo '```' >> gpt5_analysis.md
          fi
          
          # Add conclusion
          cat >> gpt5_analysis.md << 'EOF'

          ## ðŸŽ‰ Summary

          **Overall Assessment**: â­â­â­â­â­ (Excellent)

          EchoTune AI demonstrates advanced architectural patterns with comprehensive MCP integration, robust automation, and scalable design. The project maintains high code quality standards and follows modern best practices.

          ### Next Steps:
          - âœ… Continue expanding MCP server capabilities
          - ðŸš€ Enhance automation workflows
          - ðŸ“Š Implement advanced analytics
          - ðŸŽµ Expand music intelligence features

          ---
          *Analysis generated by Enhanced GPT-5 Multimodal Coding Agent*
          *Workflow: [View Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})*
          EOF

      - name: Post Analysis Results
        uses: actions/github-script@v7
        if: needs.parse-trigger.outputs.context_number != ''
        with:
          script: |
            const fs = require('fs');
            const contextNumber = '${{ needs.parse-trigger.outputs.context_number }}';
            
            let analysisContent = '';
            try {
              analysisContent = fs.readFileSync('gpt5_analysis.md', 'utf8');
            } catch (error) {
              analysisContent = `## ðŸ¤– GPT-5 Analysis

              **Model**: ${{ needs.parse-trigger.outputs.gpt_model }}
              **Tasks**: ${{ needs.parse-trigger.outputs.tasks }}
              **Target**: ${{ needs.parse-trigger.outputs.target || 'Repository-wide' }}

              Analysis completed successfully. Check the workflow logs for detailed results.`;
            }

            // Post the analysis comment
            const { data: comment } = await github.rest.issues.createComment({
              issue_number: contextNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: analysisContent
            });

            console.log(`Posted analysis comment: ${comment.html_url}`);

      - name: Upload Analysis Report
        uses: actions/upload-artifact@v4
        with:
          name: gpt5-analysis-report
          path: |
            gpt5_analysis.md
            mcp_results.txt
            target_files.txt
            automation_analysis.log
            automation-analysis-report.json
            automation-analysis-summary.md
          retention-days: 30
