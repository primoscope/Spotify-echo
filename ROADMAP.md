# EchoTune AI — Roadmap (Human Maintained)

This document is the source of truth for planning and progress. It references `ROADMAP_AUTO.md` (auto-updated via Perplexity Sonar‑Pro + Grok‑4) and captures decisions, owners, and statuses.

See also: `WORKFLOW_STATE.md` for ongoing work logs and validations.

## Pillars & Objectives

### 1) Advanced AI Integration
- Multi-Provider Support (OpenAI GPT‑4o, Google Gemini 2.0, OpenRouter Claude 3.5) with runtime switching
- Intelligent Music Conversations (natural language queries)
- Context‑Aware Recommendations & explainability
- Real‑time Provider Testing (latency, health, error rates)

### 2) Smart Music Discovery
- Spotify OAuth, playlist creation, streaming
- Discovery modes (smart/mood/trending/social/AI radio)
- ML recommendations (CF + content‑based)
- Audio feature analysis (tempo/energy/valence)

### 3) Analytics Dashboard
- Live MongoDB stats, system performance, 8‑category health
- Listening patterns, engagement KPIs

### 4) Advanced Configuration
- Enhanced settings UI (glassmorphism)
- LLM provider manager, DB tools, health monitors

---

## Performance (standing lane)
- Targets:
  - API p95: chat/providers < 800ms; analytics/dashboard < 1200ms; music/discover < 1500ms (dev env)
  - Frontend bundle: total JS < 500kB gzip; top chunk < 120kB gzip
- Automation:
  - scripts/bench/api-latency.js — measure p50/p95/min/max per endpoint (local)
  - scripts/ui/bundle-stats.js — summarize dist bundle sizes
  - sonar-project.properties — baseline static analysis and coverage mapping
- Next steps:
  - [ ] Add simple request timing middleware per route and persist rolling window to memory/Redis
  - [ ] Capture baseline metrics in test-results/ and append summary to WORKFLOW_STATE.md after builds

---

## Roadmap (Milestones)

### M0 — Foundations (complete)
- [x] Perplexity provider in prompt executor with retry/backoff, debug logs
- [x] In‑app Perplexity research endpoint (POST /api/settings/llm-providers/perplexity/research)
- [x] Cursor workflows: Browser Research, PR Deep‑Dive
- [x] CI caches (npm/pip) and nightly canary
- [x] Auto roadmap refresh (`ROADMAP_AUTO.md`) with Sonar‑Pro + Grok‑4 fallback
- [x] Cursor Background Agent & MCP env scaffolding (`env.example`, `env.template`, `PROJECT_CONFIG.md`) — owner: agent — 2025‑08‑16

### M1 — Provider Registry & Switching (WIP)
- [ ] Backend endpoints: GET /providers, POST /providers/switch, GET /providers/health (latency/error stats)
- [ ] Persist last N latency/error metrics for charts
- [ ] Frontend ProviderPanel: list/switch providers, show live metrics
- [ ] Tests for switching and telemetry

### M2 — Context‑Aware Conversations
- [ ] Backend chat pipeline: attach user context (mood/history/preferences); persist summaries
- [ ] Frontend ChatInterface/EnhancedChatInterface: context toggle, explainability view
- [ ] Verify opt‑out behavior and persistence

### M3 — Discovery Modes & Audio Features
- [ ] Server logic (music‑discovery.js, recommendations.js) for smart/mood/trending/social/AI radio
- [ ] Use src/spotify/* to compute audio features and store for ranking/visualization
- [ ] Frontend EnhancedMusicDiscovery: mode selection, feature charts, playlist creation

### M4 — Analytics Dashboard
- [ ] Backend analytics.js/insights.js endpoints for MongoDB stats, health, engagement KPIs, listening patterns
- [ ] Frontend EnhancedAnalyticsDashboard: charts and health widgets, MCP automation status

### M5 — Advanced Configuration
- [ ] Backend settings.js/admin.js: validate/apply provider configs and DB ops
- [ ] Frontend EnhancedAdvancedSettings: provider selection, params, key validation, DB ops, health thresholds

### M6 — Quality & CI
- [ ] sonar-project.properties; npm scripts for lint/test/typecheck/scan:sonar
- [ ] Optional CI Sonar workflow (guarded by SONAR_TOKEN)

---

## UI Agent

- Current Focus (2025‑08‑16):
  - Advanced AI Integration: Provider quick-switch in chat, provider badge.
  - Smart Music Discovery: Mood sliders + mini feature visualization (client-only).
  - Analytics Dashboard: Compact sparkline widgets for top metrics (client-only).
  - Advanced Configuration: Minor glass UI polish; no API changes.

- Next UI Tasks:
  1) EnhancedChatInterface.jsx: add provider quick-switch using `useLLM()`; show current provider chip.
  2) EnhancedMusicDiscovery.jsx: add client-only radar/sparkline for `moodSettings` values.
  3) EnhancedAnalyticsDashboard.jsx: add sparkline components for overview metrics using mock fallback data.

- Research-derived improvements (Perplexity):
  - Add provider/MCP observability: lightweight structured logging hooks from UI actions to backend logs.
  - Surface MCP health in UI (done in `ProviderPanel.jsx`), and add alerts if status != healthy.
  - Keep Cursor research/PR workflows discoverable in Settings/Docs panel.

- Coordination to CLI Agent (create endpoints, no UI block):
  - Unified providers API: GET `/api/providers`, POST `/api/providers/switch`, GET `/api/providers/health` with telemetry persistence.

---

## CLI Agent Tasks (API contracts)

- Providers — list
  - Method: GET `/api/providers`
  - Response (200):
```json
{
  "success": true,
  "providers": [
    {
      "id": "gemini",
      "name": "Google Gemini",
      "available": true,
      "status": "connected",
      "model": "gemini-1.5-flash",
      "performance": { "averageLatency": 1200, "successRate": 99.1, "requests": 542 }
    },
    {
      "id": "openrouter",
      "name": "OpenRouter",
      "available": false,
      "status": "no_key"
    },
    { "id": "mock", "name": "Demo Mode (Mock)", "available": true, "status": "connected" }
  ]
}
```

- Providers — switch
  - Method: POST `/api/providers/switch`
  - Request:
```json
{ "provider": "gemini", "model": "gemini-1.5-flash" }
```
  - Response (200):
```json
{ "success": true, "current": { "provider": "gemini", "model": "gemini-1.5-flash" } }
```
  - Errors: 400 if unknown provider/model; 409 if unavailable.

- Providers — health
  - Method: GET `/api/providers/health`
  - Response (200):
```json
{
  "success": true,
  "status": "healthy",
  "providers": {
    "gemini": { "status": "connected", "averageLatency": 1180, "requests": 1203, "successRate": 99.0 },
    "openai": { "status": "error", "error": "auth_error" },
    "openrouter": { "status": "no_key" },
    "mock": { "status": "connected" }
  },
  "timestamp": "2025-08-16T05:30:00Z"
}
```

Notes:
- Implement in `src/api/routes/llm-providers.js` (new top-level routes `/api/providers*`) delegating to `src/chat/llm-provider-manager.js`.
- Persist last N latency/error metrics for charts; shape matches `ProviderPanel.jsx` expectations.

---

## Research & Decisions
- Auto research (`ROADMAP_AUTO.md`) feeds tasks weekly. Significant decisions are copied here with dates and commit refs.

- 2025‑08‑16: Adopt Perplexity Sonar‑Pro for fast synthesis; Grok‑4 deep‑dive with fallback policy (commit a1686eb).
- 2025‑08‑16: Enable Perplexity debug logging and latency metrics in executor (commit 3837005).
- 2025‑08‑16: Background agent env standardized; documented in `PROJECT_CONFIG.md` (commit pending).

---

## Owners & Cadence
- Owner: agent (autonomous)
- Cadence: Nightly canary; Daily status heartbeat; Weekly roadmap refresh