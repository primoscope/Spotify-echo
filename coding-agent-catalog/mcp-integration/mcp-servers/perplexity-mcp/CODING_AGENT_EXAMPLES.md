# Enhanced Perplexity MCP Server - Coding Agent Sample Prompts

This document provides comprehensive examples of how to use the Enhanced Perplexity MCP Server with GitHub Copilot coding agents, Cursor IDE, and other MCP-compatible tools.

## üéØ Quick Start Examples

### Basic Research Query
```
Use perplexity-enhanced to research "latest Node.js security best practices 2024" with sonar-pro model
```

### Model Comparison
```
Compare models grok-4, sonar-pro, and GPT-5 for the query "implementing OAuth 2.0 in microservices architecture" focusing on latency, cost, and quality metrics
```

### Workflow Optimization
```
Generate an optimized workflow for code_review task with enterprise complexity, optimizing for comprehensive_research and accuracy
```

## üî¨ Advanced Research Workflows

### 1. Technical Research with Multiple Models
```markdown
@copilot I need comprehensive research on GraphQL federation patterns. Use the perplexity-enhanced server to:

1. Compare grok-4, sonar-pro, and GPT-5 models for this query:
   "GraphQL federation best practices, performance optimization, and enterprise implementation patterns"

2. Focus on these metrics: latency, cost, quality, citations

3. Generate an optimized workflow for research complexity: enterprise with goals: comprehensive_research, accuracy

4. Provide specific recommendations based on the comparison results
```

**Expected Response:**
- Model comparison showing which performs best for technical content
- Cost vs quality analysis 
- Recommended approach for this type of research
- Specific technical insights from multiple model perspectives

### 2. Debugging Workflow Optimization
```markdown
@copilot I'm dealing with intermittent Node.js memory leaks in production. Use perplexity-enhanced to:

1. Create an optimized debugging workflow for:
   - Task type: debugging  
   - Complexity: complex
   - Optimization goals: speed, accuracy

2. Research using the recommended model from the workflow:
   "Node.js memory leak detection tools, heap dump analysis, and production debugging strategies 2024"

3. Include domain filters for: stackoverflow.com, nodejs.org, github.com

4. Provide step-by-step debugging approach based on the research
```

**Expected Response:**
- Optimized workflow configuration suggesting best model and parameters
- Targeted research results from authoritative sources
- Step-by-step debugging methodology
- Tool recommendations and implementation guidance

### 3. Architecture Decision with Comprehensive Analysis
```markdown
@copilot We're choosing between microservices and monolith architecture for a new project. Use perplexity-enhanced to:

1. Generate workflow optimization for:
   - Task type: research
   - Complexity: enterprise  
   - Goals: comprehensive_research, accuracy

2. Execute model comparison with GPT-5, grok-4, sonar-reasoning-pro for:
   "Microservices vs monolith architecture 2024: performance, scalability, development team size, maintenance costs, deployment complexity"

3. Use recency filter: month (for latest insights)

4. Synthesize results into pros/cons matrix with specific recommendations
```

## üöÄ Performance Optimization Workflows

### 4. Code Review Enhancement
```markdown
@copilot Review this PR for performance and security issues. Use perplexity-enhanced to:

1. Get optimized workflow for code_review, complexity: moderate, goals: accuracy, comprehensive_research

2. Research specific patterns found in the code:
   - "Express.js security middleware best practices 2024"  
   - "Node.js async/await performance optimization"
   - "Database connection pooling Node.js production"

3. Use model: sonar-reasoning-pro for structured analysis

4. Provide actionable recommendations with code examples
```

### 5. Technology Stack Research
```markdown
@copilot We need to choose a frontend framework for a data-intensive dashboard. Use perplexity-enhanced to:

1. Compare all available models (grok-4, sonar-pro, GPT-5, etc.) for query:
   "React vs Vue vs Angular 2024: performance benchmarks, learning curve, enterprise adoption, data visualization capabilities"

2. Include metrics: latency, cost, quality, citations

3. Use workflow optimization for feature_development, enterprise complexity

4. Focus research on recent performance benchmarks and real-world case studies
```

## üîß Automation and Integration Patterns

### 6. Automated Code Quality Assessment
```markdown
@copilot Set up automated research for code quality improvements. Use perplexity-enhanced to:

1. Create workflow for task: code_review, complexity: moderate, goals: automation, accuracy

2. Research implementation approaches:
   "Automated code quality gates, ESLint rules enterprise, SonarQube integration CI/CD"

3. Use cost-efficient model (sonar-pro) for initial research

4. Generate implementation checklist with specific tools and configurations
```

### 7. Continuous Learning and Best Practices
```markdown
@copilot Create a learning plan for staying current with backend technologies. Use perplexity-enhanced to:

1. Research with model comparison (focus on comprehensiveness):
   "Backend development trends 2024, emerging technologies, developer skill roadmap"

2. Generate optimized workflow for research, complexity: enterprise, goals: comprehensive_research

3. Use recency filter: week for latest trends

4. Create structured learning path with resources and timelines
```

## üéØ Specialized Use Cases

### 8. Security Vulnerability Research
```markdown
@copilot Investigate potential security issues in our authentication system. Use perplexity-enhanced to:

1. Optimize workflow for debugging, complexity: complex, goals: accuracy, speed

2. Research using recommended model:
   "JWT token security vulnerabilities 2024, OAuth 2.0 attack vectors, session management best practices"

3. Filter domains: owasp.org, auth0.com, security.stackexchange.com

4. Provide immediate action items and long-term security improvements
```

### 9. Performance Benchmarking Research
```markdown
@copilot We need to optimize our API response times. Use perplexity-enhanced to:

1. Compare models for technical depth on:
   "API performance optimization techniques, database query optimization, caching strategies, CDN implementation"

2. Use workflow: research, enterprise, goals: comprehensive_research, accuracy

3. Focus on metrics that include performance benchmarks and real-world case studies

4. Generate performance improvement roadmap with measurable targets
```

### 10. Legacy System Migration Planning
```markdown
@copilot Plan migration from legacy PHP system to Node.js. Use perplexity-enhanced to:

1. Research with GPT-5 (for comprehensive analysis):
   "PHP to Node.js migration strategies, data migration approaches, gradual migration patterns, team training"

2. Create workflow for feature_development, enterprise complexity

3. Include risk assessment research:
   "Enterprise system migration risks, downtime prevention, rollback strategies"

4. Provide detailed migration timeline and resource requirements
```

## üìä Cost and Performance Examples

### Budget-Conscious Research
```markdown
@copilot Quick research on new JavaScript features (budget: $0.10). Use perplexity-enhanced to:

1. Use cost-efficient model: llama-3.1-sonar-small-128k-online
2. Query: "JavaScript ES2024 new features, performance improvements"
3. Max tokens: 1000
4. Expected cost: ~$0.002-0.004
```

### Premium Quality Research  
```markdown
@copilot Comprehensive analysis for enterprise architecture decision (budget: $0.50). Use perplexity-enhanced to:

1. Use premium model: GPT-5 
2. Enable parallel processing with multiple models
3. Query: "Enterprise software architecture patterns, scalability, cloud-native design"
4. Max tokens: 4000
5. Expected cost: ~$0.024-0.048
```

## üîç Troubleshooting and Optimization

### Model Selection Guidelines

**Use grok-4 when:**
- Need real-time data and advanced reasoning
- Working on complex coding problems
- Require mathematical or logical analysis
- Budget allows for premium performance

**Use sonar-pro when:**
- Need balanced performance and cost
- General research and documentation
- Require web search with citations
- Most common use case

**Use GPT-5 when:**
- Enterprise-level decisions required
- Need highest quality analysis
- Working on complex architectural decisions
- Budget allows for premium quality

**Use sonar-reasoning-pro when:**
- Need step-by-step problem solving
- Complex debugging workflows
- Structured analysis required

**Use llama-3.1-sonar-small when:**
- Quick lookups and simple queries
- Cost efficiency is primary concern
- Fast response time needed

### Performance Optimization Tips

1. **Use appropriate complexity levels:**
   - Simple: Basic queries, quick lookups
   - Moderate: Standard development tasks  
   - Complex: Advanced technical problems
   - Enterprise: Mission-critical decisions

2. **Optimize for specific goals:**
   - Speed: Use smaller models, reduce tokens
   - Cost: Use efficient models, enable caching
   - Accuracy: Use premium models, increase tokens
   - Comprehensive: Enable parallel processing

3. **Enable caching for repeated queries:**
   - Set up Redis for distributed caching
   - Use semantic similarity for related queries
   - Monitor cache hit rates for optimization

## üìà Success Metrics

Track these metrics to optimize your usage:

- **Response Quality**: 8+ rating on 10-point scale
- **Cost Efficiency**: Stay within daily/session budgets
- **Response Time**: <3000ms for most queries
- **Cache Hit Rate**: >30% for repeated patterns
- **Model Selection**: Use appropriate tier for task complexity

## üéâ Advanced Integration Examples

### GitHub Actions Integration
```yaml
name: Enhanced Research Workflow
on: 
  pull_request:
    types: [opened, synchronize]

jobs:
  research:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Dependencies
        run: npm install
      
      - name: Run Enhanced Perplexity Research
        env:
          PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
        run: |
          node -e "
          const Server = require('./mcp-servers/perplexity-mcp/perplexity-mcp-server.js');
          const server = new Server();
          server.initializeRedis().then(() => {
            return server.handleResearch({
              q: 'Best practices for ${{ github.event.pull_request.title }}',
              opts: { model: 'sonar-pro', max_tokens: 1500 }
            });
          }).then(result => {
            console.log('Research Results:', result.content[0].text.substring(0, 500));
          });
          "
```

### VS Code Extension Integration
```javascript
// Example VS Code extension using Enhanced Perplexity MCP
const vscode = require('vscode');

async function researchCurrentFunction() {
    const editor = vscode.window.activeTextEditor;
    const selection = editor.selection;
    const selectedText = editor.document.getText(selection);
    
    // Use MCP client to call enhanced perplexity server
    const result = await mcpClient.callTool('model_comparison', {
        q: `Explain and optimize this code: ${selectedText}`,
        models: ['grok-4', 'sonar-pro'],
        metrics: ['quality', 'cost']
    });
    
    // Display results in VS Code
    vscode.window.showInformationMessage(result.content[0].text.substring(0, 200));
}
```

---

*These examples demonstrate the full capabilities of the Enhanced Perplexity MCP Server. Adjust model selection, complexity, and optimization goals based on your specific needs and budget constraints.*