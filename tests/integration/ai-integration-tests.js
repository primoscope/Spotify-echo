/**
 * Comprehensive AI Integration Test Suite
 * 
 * Tests:
 * - Perplexity Sonar Pro API connectivity and responses
 * - Advanced AI Integration (Perplexity-based) functionality
 * - MCP server integrations and tool calls
 * - Multi-model orchestration workflows
 * - Automated research pipeline
 * - Continuous learning system
 * - Cursor configuration validation
 * - Performance and reliability metrics
 */

const { describe, test, beforeAll, afterAll, beforeEach, expect, jest } = require('@jest/globals');
const fs = require('fs').promises;
const path = require('path');
const AutomatedResearchPipeline = require('../../scripts/automated-research-pipeline');
const MultiModelOrchestrator = require('../../scripts/multi-model-orchestrator');
const ContinuousLearningSystem = require('../../scripts/continuous-learning-system');

// Test configuration
const TEST_CONFIG = {
  timeout: 30000,
  maxRetries: 3,
  endpoints: {
    perplexity: 'https://api.perplexity.ai',
    localhost: 'http://localhost:3000'
  },
  testData: {
    sampleCode: 'const test = () => { return "Hello World"; }',
    sampleQuery: 'What are the best practices for React hooks?',
    sampleContext: {
      technology: 'React',
      framework: 'React 19',
      complexity: 'medium'
    }
  }
};

describe('AI Integration Test Suite', () => {
  let researchPipeline;
  let orchestrator;
  let learningSystem;
  let testResults = {
    perplexity: { passed: 0, failed: 0 },
    advancedAI: { passed: 0, failed: 0 },
    mcp: { passed: 0, failed: 0 },
    workflows: { passed: 0, failed: 0 },
    performance: { passed: 0, failed: 0 }
  };

  beforeAll(async () => {
    console.log('üß™ Initializing AI Integration Test Suite...');
    
    // Initialize systems
    researchPipeline = new AutomatedResearchPipeline();
    orchestrator = new MultiModelOrchestrator({
      metricsEnabled: true,
      cacheEnabled: false // Disable cache for testing
    });
    learningSystem = new ContinuousLearningSystem({
      dataDirectory: '.cursor/test-learning-data'
    });

    // Wait for initialization
    await new Promise(resolve => setTimeout(resolve, 2000));
  });

  afterAll(async () => {
    console.log('üßπ Cleaning up test environment...');
    
    if (orchestrator) {
      orchestrator.cleanup();
    }
    
    // Clean up test data
    try {
      await fs.rmdir('.cursor/test-learning-data', { recursive: true });
    } catch (error) {
      // Ignore cleanup errors
    }

    // Print test results summary
    console.log('\nüìä Test Results Summary:');
    Object.entries(testResults).forEach(([category, results]) => {
      const total = results.passed + results.failed;
      const successRate = total > 0 ? (results.passed / total * 100).toFixed(1) : '0.0';
      console.log(`  ${category}: ${results.passed}/${total} passed (${successRate}%)`);
    });
  });

  describe('Perplexity Sonar Pro Integration', () => {
    test('should validate API configuration', async () => {
      try {
        const hasApiKey = !!process.env.PERPLEXITY_API_KEY;
        expect(hasApiKey).toBe(true);
        
        testResults.perplexity.passed++;
      } catch (error) {
        testResults.perplexity.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should handle research queries correctly', async () => {
      try {
        const result = await researchPipeline.researchBestPractices(
          'React',
          'component optimization'
        );
        
        expect(result).toBeDefined();
        expect(result.success).toBe(true);
        expect(result.data).toBeDefined();
        
        testResults.perplexity.passed++;
      } catch (error) {
        testResults.perplexity.failed++;
        console.warn('‚ö†Ô∏è Perplexity research test failed (likely due to API key):', error.message);
        // Don't fail the test if it's an API key issue
        if (!error.message.includes('API key')) {
          throw error;
        }
      }
    }, TEST_CONFIG.timeout);

    test('should cache results appropriately', async () => {
      try {
        const query = TEST_CONFIG.testData.sampleQuery;
        
        // First call
        const start1 = Date.now();
        await researchPipeline.researchBestPractices('React', 'hooks');
        const duration1 = Date.now() - start1;
        
        // Second call (should be faster due to caching)
        const start2 = Date.now();
        await researchPipeline.researchBestPractices('React', 'hooks');
        const duration2 = Date.now() - start2;
        
        // Cache should make second call faster (if not mocked)
        console.log(`Cache test: First call ${duration1}ms, Second call ${duration2}ms`);
        
        testResults.perplexity.passed++;
      } catch (error) {
        testResults.perplexity.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should handle security analysis requests', async () => {
      try {
        const result = await researchPipeline.analyzeSecurity(
          'user authentication system',
          ['user input', 'database storage', 'API response']
        );
        
        expect(result).toBeDefined();
        
        testResults.perplexity.passed++;
      } catch (error) {
        testResults.perplexity.failed++;
        if (!error.message.includes('API key')) {
          throw error;
        }
      }
    }, TEST_CONFIG.timeout);
  });

  describe('Advanced AI Integration (Perplexity-based)', () => {
    test('should route tasks correctly based on complexity', async () => {
      try {
        const simpleTask = {
          type: 'simple',
          complexity: 'low',
          description: 'Simple code fix',
          budgetSensitive: true
        };
        
        const complexTask = {
          type: 'architecture',
          complexity: 'high',
          description: 'System architecture design',
          requiresArchitecture: true
        };
        
        const simpleRoute = orchestrator.routeTask(simpleTask);
        const complexRoute = orchestrator.routeTask(complexTask);
        
        expect(simpleRoute).toBe('gpt-4-mini');
        expect(complexRoute).toBe('advanced-ai');
        
        testResults.advancedAI.passed++;
      } catch (error) {
        testResults.advancedAI.failed++;
        throw error;
      }
    });

    test('should execute tasks with proper model selection', async () => {
      try {
        const task = {
          type: 'code-analysis',
          description: 'Analyze React component',
          complexity: 'medium',
          requiresCode: true
        };
        
        const result = await orchestrator.executeTask(task);
        
        expect(result).toBeDefined();
        expect(result.modelId).toBeDefined();
        expect(result.confidence).toBeGreaterThan(0);
        
        testResults.advancedAI.passed++;
      } catch (error) {
        testResults.advancedAI.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should handle consensus checking', async () => {
      try {
        const task = {
          type: 'architecture',
          description: 'Design microservices architecture',
          complexity: 'high',
          requiresArchitecture: true
        };
        
        const consensus = await orchestrator.executeWithConsensus(task);
        
        expect(consensus).toBeDefined();
        expect(consensus.score).toBeGreaterThanOrEqual(0);
        expect(consensus.results).toBeDefined();
        expect(Array.isArray(consensus.results)).toBe(true);
        
        testResults.advancedAI.passed++;
      } catch (error) {
        testResults.advancedAI.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should handle parallel execution', async () => {
      try {
        const tasks = [
          {
            type: 'generation',
            description: 'Generate React component',
            requiresCode: true
          },
          {
            type: 'research',
            description: 'Research best practices',
            requiresResearch: true
          },
          {
            type: 'simple',
            description: 'Simple utility function',
            complexity: 'low'
          }
        ];
        
        const results = await orchestrator.executeParallel(tasks);
        
        expect(results).toBeDefined();
        expect(Array.isArray(results)).toBe(true);
        expect(results.length).toBe(tasks.length);
        
        testResults.advancedAI.passed++;
      } catch (error) {
        testResults.advancedAI.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);
  });

  describe('MCP Server Integration', () => {
    test('should validate MCP configuration', async () => {
      try {
        const mcpConfigPath = path.join(process.cwd(), '.cursor', 'mcp.json');
        const mcpConfig = JSON.parse(await fs.readFile(mcpConfigPath, 'utf8'));
        
        expect(mcpConfig.mcpServers).toBeDefined();
        expect(mcpConfig.mcpServers['perplexity-ask']).toBeDefined();
        expect(mcpConfig.mcpServers['advanced-ai-integration']).toBeDefined();
        
        // Validate required environment variables
        const perplexityServer = mcpConfig.mcpServers['perplexity-ask'];
        expect(perplexityServer.env.PERPLEXITY_API_KEY).toBe('${PERPLEXITY_API_KEY}');
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });

    test('should validate MCP server file existence', async () => {
      try {
        const servers = [
          './mcp-servers/perplexity-ask-server/perplexity-ask-mcp.js',
          './src/api/ai-integration/grok4-mcp-server.js'
        ];
        
        for (const serverPath of servers) {
          const fullPath = path.join(process.cwd(), serverPath);
          const exists = await fs.access(fullPath).then(() => true).catch(() => false);
          expect(exists).toBe(true);
        }
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });

    test('should validate workflow configurations', async () => {
      try {
        const workflowPath = path.join(process.cwd(), '.cursor', 'workflows', 'ai-research-automation.json');
        const exists = await fs.access(workflowPath).then(() => true).catch(() => false);
        
        if (exists) {
          const workflows = JSON.parse(await fs.readFile(workflowPath, 'utf8'));
          expect(workflows.workflows).toBeDefined();
          expect(Array.isArray(workflows.workflows)).toBe(true);
          
          // Check for key workflows
          const workflowNames = workflows.workflows.map(w => w.name);
          expect(workflowNames).toContain('competitive-analysis-workflow');
          expect(workflowNames).toContain('security-vulnerability-research');
        }
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });
  });

  describe('Research Pipeline Workflows', () => {
    test('should execute new feature pipeline', async () => {
      try {
        const context = {
          technology: 'React',
          feature: 'user authentication',
          data_flow: ['login form', 'API validation', 'token storage']
        };
        
        const result = await researchPipeline.executePipeline('new-feature', context);
        
        expect(result).toBeDefined();
        expect(result.research).toBeDefined();
        expect(result.security).toBeDefined();
        expect(result.patterns).toBeDefined();
        expect(result.recommendations).toBeDefined();
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should execute security review pipeline', async () => {
      try {
        const context = {
          code_paths: ['src/auth/login.js', 'src/api/auth.js'],
          standards: ['OWASP', 'GDPR'],
          architecture: 'microservices'
        };
        
        const result = await researchPipeline.executePipeline('security-review', context);
        
        expect(result).toBeDefined();
        expect(result.vulnerability_scan).toBeDefined();
        expect(result.compliance_check).toBeDefined();
        expect(result.threat_modeling).toBeDefined();
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should execute performance optimization pipeline', async () => {
      try {
        const context = {
          metrics: {
            responseTime: 2500,
            memoryUsage: 512,
            cpuUsage: 85
          }
        };
        
        const result = await researchPipeline.executePipeline('performance-optimization', context);
        
        expect(result).toBeDefined();
        expect(result.performance_analysis).toBeDefined();
        expect(result.bottleneck_identification).toBeDefined();
        expect(result.optimization_strategies).toBeDefined();
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should cache pipeline results', async () => {
      try {
        // Execute pipeline twice and verify caching
        const context = { technology: 'Node.js', feature: 'API endpoint' };
        
        const result1 = await researchPipeline.executePipeline('new-feature', context);
        const result2 = await researchPipeline.executePipeline('new-feature', context);
        
        expect(result1).toBeDefined();
        expect(result2).toBeDefined();
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    });
  });

  describe('Continuous Learning System', () => {
    test('should record successful implementations', async () => {
      try {
        await learningSystem.recordSuccess({
          description: 'React component optimization test',
          technology: 'React',
          framework: 'React 19',
          code: TEST_CONFIG.testData.sampleCode,
          metrics: { responseTime: 800, memoryUsage: 100 }
        });
        
        expect(learningSystem.successPatterns.size).toBeGreaterThanOrEqual(0);
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    });

    test('should record and analyze failures', async () => {
      try {
        await learningSystem.recordFailure({
          description: 'Database connection test failure',
          technology: 'MongoDB',
          error: 'Connection timeout after 5000ms',
          context: { environment: 'test' }
        });
        
        expect(learningSystem.failurePatterns.size).toBeGreaterThanOrEqual(0);
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    });

    test('should process feedback correctly', async () => {
      try {
        await learningSystem.processFeedback({
          type: 'positive',
          content: 'Test feedback for integration',
          confidence: 0.8,
          source: 'test'
        });
        
        expect(learningSystem.feedbackQueue.length).toBeGreaterThan(0);
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    });

    test('should generate recommendations', async () => {
      try {
        const recommendations = await learningSystem.getRecommendations(
          TEST_CONFIG.testData.sampleContext
        );
        
        expect(Array.isArray(recommendations)).toBe(true);
        
        testResults.workflows.passed++;
      } catch (error) {
        testResults.workflows.failed++;
        throw error;
      }
    });
  });

  describe('Performance and Reliability', () => {
    test('should meet response time requirements', async () => {
      try {
        const task = {
          type: 'simple',
          description: 'Performance test task',
          complexity: 'low'
        };
        
        const start = Date.now();
        const result = await orchestrator.executeTask(task);
        const duration = Date.now() - start;
        
        expect(result).toBeDefined();
        expect(duration).toBeLessThan(5000); // 5 second timeout for tests
        
        testResults.performance.passed++;
      } catch (error) {
        testResults.performance.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);

    test('should handle errors gracefully', async () => {
      try {
        const invalidTask = {
          type: 'invalid',
          description: 'This should fail gracefully'
        };
        
        const result = await orchestrator.executeTask(invalidTask);
        
        // Should still return a result or handle gracefully
        expect(result).toBeDefined();
        
        testResults.performance.passed++;
      } catch (error) {
        // Graceful error handling is acceptable
        expect(error.message).toBeDefined();
        testResults.performance.passed++;
      }
    });

    test('should maintain metrics correctly', async () => {
      try {
        const metrics = orchestrator.getMetrics();
        
        expect(metrics).toBeDefined();
        expect(typeof metrics.totalRequests).toBe('number');
        expect(typeof metrics.successfulRequests).toBe('number');
        expect(typeof metrics.failedRequests).toBe('number');
        expect(typeof metrics.successRate).toBe('number');
        
        testResults.performance.passed++;
      } catch (error) {
        testResults.performance.failed++;
        throw error;
      }
    });

    test('should handle concurrent requests', async () => {
      try {
        const tasks = Array(5).fill(null).map((_, index) => ({
          type: 'simple',
          description: `Concurrent test task ${index}`,
          complexity: 'low'
        }));
        
        const promises = tasks.map(task => orchestrator.executeTask(task));
        const results = await Promise.all(promises);
        
        expect(results.length).toBe(tasks.length);
        results.forEach(result => {
          expect(result).toBeDefined();
        });
        
        testResults.performance.passed++;
      } catch (error) {
        testResults.performance.failed++;
        throw error;
      }
    }, TEST_CONFIG.timeout);
  });

  describe('Configuration Validation', () => {
    test('should validate .cursorrules configuration', async () => {
      try {
        const cursorRulesPath = path.join(process.cwd(), '.cursorrules');
        const cursorRules = await fs.readFile(cursorRulesPath, 'utf8');
        
        expect(cursorRules).toContain('Enhanced Cursor Rules');
        expect(cursorRules).toContain('Advanced AI Model Selection');
        expect(cursorRules).toContain('Enhanced Context Management');
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });

    test('should validate .cursorignore patterns', async () => {
      try {
        const cursorIgnorePath = path.join(process.cwd(), '.cursorignore');
        const exists = await fs.access(cursorIgnorePath).then(() => true).catch(() => false);
        
        if (exists) {
          const cursorIgnore = await fs.readFile(cursorIgnorePath, 'utf8');
          expect(cursorIgnore).toContain('node_modules');
          expect(cursorIgnore).toContain('dist');
        }
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });

    test('should validate environment variables', async () => {
      try {
        const requiredEnvVars = ['PERPLEXITY_API_KEY'];
        const missingVars = [];
        
        requiredEnvVars.forEach(varName => {
          if (!process.env[varName]) {
            missingVars.push(varName);
          }
        });
        
        if (missingVars.length > 0) {
          console.warn(`‚ö†Ô∏è Missing environment variables: ${missingVars.join(', ')}`);
          // Don't fail test for missing env vars in CI
        }
        
        testResults.mcp.passed++;
      } catch (error) {
        testResults.mcp.failed++;
        throw error;
      }
    });
  });
});

// Test helper functions
async function validateApiEndpoint(url) {
  try {
    // In a real implementation, this would make an actual HTTP request
    return { status: 'available', url };
  } catch (error) {
    return { status: 'unavailable', url, error: error.message };
  }
}

async function measureResponseTime(fn) {
  const start = Date.now();
  const result = await fn();
  const duration = Date.now() - start;
  return { result, duration };
}

module.exports = {
  TEST_CONFIG,
  validateApiEndpoint,
  measureResponseTime
};